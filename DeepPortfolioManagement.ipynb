{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd04bdc6f543d21430f19fdc68f48a348338922fbb620c2c2e274fc8ce374f8d71d",
   "display_name": "Python 3.8.8 64-bit ('torch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import random\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pybithumb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "# define global variables\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"using {DEVICE}\")\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE= 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "def preprocess(sample):\n",
    "    sample[\"open_lclose_ratio\"] = sample['open']/sample['close'].shift(1)\n",
    "    sample[\"high_close_ratio\"] = sample['high']/sample['close']\n",
    "    sample['low_close_ratio'] = sample['low']/sample['close']\n",
    "    sample['close_lclose_ratio'] = sample['close']/sample['close'].shift(1)\n",
    "    sample['volume_lvolume_ratio'] = sample['volume']/sample['volume'].shift(1)\n",
    "    sample['close_ma5_ratio'] = sample['close']/sample['close'].rolling(window=5).mean()\n",
    "    sample['close_ma10_ratio'] = sample['close']/sample['close'].rolling(window=10).mean()\n",
    "    sample['close_ma20_ratio'] = sample['close']/sample['close'].rolling(window=20).mean()\n",
    "    sample['close_ma60_ratio'] = sample['close']/sample['close'].rolling(window=60).mean()\n",
    "    sample['close_ma120_ratio'] = sample['close']/sample['close'].rolling(window=120).mean()\n",
    "    sample['volume_ma5_ratio'] = sample['volume']/sample['volume'].rolling(window=5).mean()\n",
    "    sample['volume_ma10_ratio'] = sample['volume']/sample['volume'].rolling(window=10).mean()\n",
    "    sample['volume_ma20_ratio'] = sample['volume']/sample['volume'].rolling(window=20).mean()\n",
    "    sample['volume_ma60_ratio'] = sample['volume']/sample['volume'].rolling(window=60).mean()\n",
    "    sample['volume_ma120_ratio'] = sample['volume']/sample['volume'].rolling(window=120).mean()\n",
    "\n",
    "    return sample.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "samples = dict()\n",
    "coins = [\"BTC\", \"ETH\", \"EOS\", \"XLM\", \"QTUM\"]\n",
    "\n",
    "connect_key = \"d5c7f4458a58322ac7573f9f8193d4f2\"\n",
    "secret_key = \"aacd7c9c31a4bbcf30d5088a1b22e338\"\n",
    "bithumb = pybithumb.Bithumb(connect_key, secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4344\n",
      "4344\n",
      "4344\n",
      "4344\n",
      "4344\n"
     ]
    }
   ],
   "source": [
    "# Preprocess samples\n",
    "samples = dict()\n",
    "\n",
    "for coin in coins:\n",
    "    temp = list()\n",
    "    sample = bithumb.get_candlestick(coin, \"KRW\", chart_intervals=\"1h\")\n",
    "    print(len(sample))\n",
    "    sample = preprocess(sample)\n",
    "    \n",
    "    for i in range(4):\n",
    "        start_cut = int(i*0.25*len(sample.index))\n",
    "        end_cut = int((i+1)*0.25*len(sample.index))\n",
    "\n",
    "        block_sample = sample.iloc[start_cut:end_cut]\n",
    "        temp.append(block_sample)\n",
    "    samples[coin] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[block 1] long: 494, hold: 562\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2c1a233da8649ad905c318d0b6456d4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8282051282051281\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.8282051282051281\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.8282051282051281\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.8305790363482671\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.830607213299521\n",
      "\n",
      "Best pipeline: XGBClassifier(input_matrix, learning_rate=0.1, max_depth=2, min_child_weight=11, n_estimators=100, n_jobs=1, subsample=0.4, verbosity=0)\n",
      "[block 1] tpot test score: 0.8862559241706162\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Optimization Progress:   0%|          | 0/60 [00:00<?, ?pipeline/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9703ff2b988447b49248a033bb6f7c4b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8306001690617075\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.832952944491406\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.832952944491406\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.832952944491406\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.8341222879684418\n",
      "\n",
      "Best pipeline: PytorchLRClassifier(RobustScaler(SelectFwe(input_matrix, alpha=0.011)), batch_size=16, learning_rate=0.1, num_epochs=5, weight_decay=0)\n",
      "block [1] clf test score: 0.8436018957345972\n",
      "[block 2] long: 535, hold: 521\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "deeea5281c7d4337b2b17bcc27925475"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8116089039165961\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.8116089039165961\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.8128134685826993\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.8128134685826993\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.8151873767258382\n",
      "\n",
      "Best pipeline: ExtraTreesClassifier(BernoulliNB(RFE(input_matrix, criterion=gini, max_features=0.1, n_estimators=100, step=0.4), alpha=10.0, fit_prior=False), bootstrap=False, criterion=entropy, max_features=0.9000000000000001, min_samples_leaf=12, min_samples_split=14, n_estimators=100)\n",
      "[block 2] tpot test score: 0.8530805687203792\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Optimization Progress:   0%|          | 0/60 [00:00<?, ?pipeline/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c40f42474a644fa9ef76206f2eb17e2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8139335023950409\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.8139335023950409\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.817483798253029\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.817483798253029\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.817483798253029\n",
      "\n",
      "Best pipeline: PytorchLRClassifier(FastICA(SelectFwe(input_matrix, alpha=0.031), tol=0.1), batch_size=8, learning_rate=0.1, num_epochs=15, weight_decay=0)\n",
      "block [2] clf test score: 0.8672985781990521\n",
      "[block 3] long: 465, hold: 591\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45cbc6fb33f9440cab8d2085b3c1adad"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.7961327134404057\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.8032403493941956\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.8032403493941956\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.8103691180614258\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.8115736827275288\n",
      "\n",
      "Best pipeline: XGBClassifier(MultinomialNB(BernoulliNB(input_matrix, alpha=10.0, fit_prior=False), alpha=10.0, fit_prior=False), learning_rate=0.5, max_depth=9, min_child_weight=13, n_estimators=100, n_jobs=1, subsample=0.45, verbosity=0)\n",
      "[block 3] tpot test score: 0.7725118483412322\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Optimization Progress:   0%|          | 0/60 [00:00<?, ?pipeline/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2ed3bc3599d47aaae324db01269a67e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8056142575373345\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.8056142575373345\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.8103832065370528\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.8139194139194139\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.8139194139194139\n",
      "\n",
      "Best pipeline: PytorchLRClassifier(RobustScaler(SelectPercentile(input_matrix, percentile=22)), batch_size=32, learning_rate=0.01, num_epochs=15, weight_decay=0.0001)\n",
      "block [3] clf test score: 0.8720379146919431\n",
      "[block 4] long: 599, hold: 458\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "764a551e864449838b3f4f3b7d79b12c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8294096928712313\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.8294237813468583\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.8294237813468583\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.8294237813468583\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.8294237813468583\n",
      "\n",
      "Best pipeline: XGBClassifier(input_matrix, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, n_jobs=1, subsample=0.05, verbosity=0)\n",
      "[block 4] tpot test score: 0.8443396226415094\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Optimization Progress:   0%|          | 0/60 [00:00<?, ?pipeline/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e1f87158f464233acd861912932dca9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8021484925331078\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.8021484925331078\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.8056706114398422\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.8140321217244294\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.8187376725838265\n",
      "\n",
      "Best pipeline: PytorchLRClassifier(RobustScaler(VarianceThreshold(input_matrix, threshold=0.0001)), batch_size=8, learning_rate=0.01, num_epochs=10, weight_decay=0.0001)\n",
      "block [4] clf test score: 0.8490566037735849\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    # get features\n",
    "    sample = samples[\"ETH\"][i].copy()\n",
    "\n",
    "    # make target\n",
    "    sample['target'] = np.nan\n",
    "    skyrocket = 0\n",
    "    stalemate = 0\n",
    "    for idx in sample.index:\n",
    "        try:\n",
    "            rtn = sample.loc[idx, 'close']/sample.shift(10).loc[idx, 'close']\n",
    "            if rtn > 1.005:\n",
    "                sample.loc[idx, 'target'] = 0\n",
    "                skyrocket += 1\n",
    "            else:\n",
    "                sample.loc[idx, 'target'] = 1\n",
    "                stalemate += 1\n",
    "        except:\n",
    "            sample.loc[idx, 'target'] = 1\n",
    "    print(f\"[block {i+1}] long: {skyrocket}, hold: {stalemate}\")\n",
    "\n",
    "    features = sample.shift(1).drop(['open', 'high', 'low', 'close', 'volume', 'target'], axis=1).dropna()\n",
    "    target = sample['target'].iloc[1:]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, train_size=0.8, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "    tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2, random_state=42)\n",
    "    tpot.fit(X_train, y_train)\n",
    "    print(f\"[block {i+1}] tpot test score: {tpot.score(X_test, y_test)}\")\n",
    "    tpot.export(f\"sample{i+1}_tpot_bestfit.py\")\n",
    "\n",
    "    clf = TPOTClassifier(config_dict=\"TPOT NN\", template=\"Selector-Transformer-PytorchLRClassifier\", generations=5, population_size=10, verbosity=2)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f\"block [{i+1}] clf test score: {clf.score(X_test, y_test)}\")\n",
    "    clf.export(f\"sample{i+1}_neuralnet_bestfit.py\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}